{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    BertTokenizer,\n",
    "    BartTokenizer,\n",
    "    T5Tokenizer,\n",
    "    GPT2Tokenizer,\n",
    ")\n",
    "from typing import Union, List, Dict, Tuple, Callable\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "# from utils import SentenceEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from typing import List, Optional\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.testing_utils import CaptureLogger\n",
    "from transformers.utils.logging import get_logger\n",
    "\n",
    "\n",
    "class DGDataset:\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataset: str = \"blended_skill_talk\",\n",
    "        task: str = \"seq2seq\",\n",
    "        tokenizer: AutoTokenizer = None,\n",
    "        max_source_length: int = 512,\n",
    "        max_target_length: int = 512,\n",
    "        padding: str = \"max_length\",\n",
    "        ignore_pad_token_for_loss: bool = True,\n",
    "        preprocessing_num_workers: int = None,\n",
    "        overwrite_cache: bool = True,\n",
    "    ):\n",
    "        self.dataset = dataset\n",
    "        self.task = task\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "        self.padding = padding\n",
    "        self.ignore_pad_token_for_loss = ignore_pad_token_for_loss\n",
    "        self.preprocessing_num_workers = preprocessing_num_workers\n",
    "        self.overwrite_cache = overwrite_cache\n",
    "        # since this will be pickled to avoid _LazyModule error in Hasher force logger loading before tokenize_function\n",
    "        self.tok_logger = get_logger(\"transformers.tokenization_utils_base\")\n",
    "\n",
    "\n",
    "    def prepare_context(self, instance: dict):\n",
    "        if self.dataset == 'blended_skill_talk':\n",
    "            num_entries = len(instance[\"free_messages\"])\n",
    "            total_entries = num_entries\n",
    "            if self.task == 'seq2seq':\n",
    "                persona_pieces = f\"<PS>{instance['personas'][1]}\"\n",
    "                if instance['context'] == \"wizard_of_wikipedia\":\n",
    "                    additional_context_pieces = f\"<CTX>{instance['additional_context']}.\"\n",
    "                else:\n",
    "                    additional_context_pieces = \"\"\n",
    "                context = persona_pieces + additional_context_pieces\n",
    "            else:\n",
    "                num_entries = min(num_entries, 2)\n",
    "                context = ''\n",
    "            prev_utt_pc = [sent for sent in instance[\"previous_utterance\"] if sent != '']\n",
    "\n",
    "        elif self.dataset == 'conv_ai_2':\n",
    "            total_entries = len(instance['dialog'])\n",
    "            num_entries = total_entries//2\n",
    "            if self.task == 'seq2seq':\n",
    "                user_profile = ' '.join([''.join(x) for x in instance['user_profile']])\n",
    "                persona_pieces = f\"<PS>{user_profile}\"\n",
    "                context = persona_pieces\n",
    "            else:\n",
    "                num_entries = min(num_entries, 2)\n",
    "                context = ''\n",
    "            prev_utt_pc = []\n",
    "\n",
    "        elif self.dataset == 'empathetic_dialogues':\n",
    "            total_entries = len(instance['dialog'])\n",
    "            num_entries = total_entries//2\n",
    "            if self.task == 'seq2seq':\n",
    "                persona_pieces = f\"<PS>{instance['prompt']}\"\n",
    "                additional_context_pieces = f\"<CTX>{instance['context']}.\"\n",
    "                context = persona_pieces + additional_context_pieces\n",
    "            else:\n",
    "                num_entries = min(num_entries, 2)\n",
    "                context = ''\n",
    "            prev_utt_pc = []\n",
    "\n",
    "        elif self.dataset == 'AlekseyKorshuk/persona-chat':\n",
    "            total_entries = len(instance['utterances'])\n",
    "            num_entries = total_entries//2\n",
    "            if self.task == 'seq2seq':\n",
    "                user_profile = ' '.join(instance['personality'])\n",
    "                persona_pieces = f\"<PS>{user_profile}\"\n",
    "                context = persona_pieces\n",
    "            else:\n",
    "                num_entries = min(num_entries, 2)\n",
    "                context = ''\n",
    "            prev_utt_pc = []\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Dataset not supported.\")\n",
    "        return num_entries, total_entries, context, prev_utt_pc\n",
    "\n",
    "\n",
    "    def prepare_entry(\n",
    "        self, \n",
    "        instance: dict, \n",
    "        entry_idx: int, \n",
    "        context: str, \n",
    "        prev_utt_pc: List[str], \n",
    "        total_entries: int,\n",
    "    ):\n",
    "        if self.dataset == 'blended_skill_talk':\n",
    "            free_message = instance['free_messages'][entry_idx]\n",
    "            guided_message = instance['guided_messages'][entry_idx]\n",
    "            references = [values[entry_idx] for key, values in instance['suggestions'].items()]\n",
    "\n",
    "        elif self.dataset == 'conv_ai_2':\n",
    "            free_message = instance['dialog'][entry_idx*2]['text']\n",
    "            if entry_idx*2+1 >= total_entries:\n",
    "                guided_message = None\n",
    "            else:\n",
    "                guided_message = instance['dialog'][entry_idx*2+1]['text']\n",
    "            references = []\n",
    "\n",
    "        elif self.dataset == 'empathetic_dialogues':\n",
    "            free_message = instance['dialog'][entry_idx*2]['text']\n",
    "            if entry_idx*2+1 >= total_entries:\n",
    "                guided_message = None\n",
    "            else:\n",
    "                guided_message = instance['dialog'][entry_idx*2+1]['text']\n",
    "            references = []\n",
    "\n",
    "        elif self.dataset == 'AlekseyKorshuk/persona-chat':\n",
    "            free_message = instance['utterances'][entry_idx*2]['history'][-1]\n",
    "            if entry_idx*2+1 >= total_entries:\n",
    "                guided_message = None\n",
    "            else:\n",
    "                guided_message = instance['utterances'][entry_idx*2+1]['history'][-1]\n",
    "            references = instance['utterances'][entry_idx*2]['candidates']\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Dataset not supported.\")\n",
    "\n",
    "        if not prev_utt_pc:\n",
    "            original_context = context\n",
    "        else:\n",
    "            sp_token = '<SEP>' if self.task == 'seq2seq' else ' '\n",
    "            original_context = context + sp_token + sp_token.join(prev_utt_pc)\n",
    "        \n",
    "        references.append(guided_message)\n",
    "        return free_message, guided_message, original_context, references\n",
    "\n",
    "\n",
    "    def tokenize_and_align_labels(self, instance: dict):\n",
    "        num_entries, total_entries, context, prev_utt_pc = self.prepare_context(instance)\n",
    "        inputs, labels = [], []\n",
    "        for entry_idx in range(num_entries):\n",
    "            free_message, guided_message, original_context, references = self.prepare_entry(\n",
    "                instance, \n",
    "                entry_idx, \n",
    "                context, \n",
    "                prev_utt_pc,\n",
    "                total_entries,\n",
    "            )\n",
    "            if guided_message is None:\n",
    "                continue\n",
    "            # Input & Output\n",
    "            if self.task == 'seq2seq':\n",
    "                text = original_context + self.tokenizer.eos_token + free_message\n",
    "            else:\n",
    "                text = original_context + free_message + guided_message\n",
    "\n",
    "            inputs.append(text)\n",
    "            labels.append(guided_message)\n",
    "            prev_utt_pc += [\n",
    "                free_message,\n",
    "                guided_message,\n",
    "            ]\n",
    "        \n",
    "        if not inputs:\n",
    "            return {\"input_ids\": [], \"labels\": [], \"attention_mask\": []}\n",
    "\n",
    "        if self.task == 'seq2seq':\n",
    "            inputs = self.tokenizer(inputs, max_length=self.max_source_length, padding=self.padding, truncation=True)\n",
    "            # Setup the tokenizer for targets\n",
    "            with self.tokenizer.as_target_tokenizer():\n",
    "                labels = self.tokenizer(labels, max_length=self.max_target_length, padding=self.padding, truncation=True)\n",
    "            \n",
    "            # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 \n",
    "            # when we want to ignore padding in the loss.\n",
    "            if self.padding == \"max_length\" and self.ignore_pad_token_for_loss:\n",
    "                labels[\"input_ids\"] = [\n",
    "                    [(l if l != self.tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "                ]\n",
    "            inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "            return inputs\n",
    "        else:\n",
    "            with CaptureLogger(self.tok_logger) as cl:\n",
    "                inputs = self.tokenizer(\n",
    "                    inputs, \n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=self.max_source_length, \n",
    "                    padding=self.padding, \n",
    "                    truncation=True,\n",
    "                )\n",
    "                labels = self.tokenizer(\n",
    "                    labels, \n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=self.max_target_length, \n",
    "                    padding=self.padding, \n",
    "                    truncation=True,\n",
    "                )\n",
    "                \n",
    "            new_inputs = inputs.copy()\n",
    "            for k, v1 in inputs.items():\n",
    "                v2 = labels[k]\n",
    "                new_inputs[k] = torch.cat((v1, v2), dim=1)\n",
    "                \n",
    "            new_labels = torch.cat((-100*torch.ones_like(inputs[\"input_ids\"]), labels[\"input_ids\"]), dim=1)\n",
    "            new_inputs[\"labels\"] = new_labels\n",
    "\n",
    "            # clm input could be much much longer than block_size\n",
    "            if \"Token indices sequence length is longer than the\" in cl.out:\n",
    "                self.tok_logger.warning(\n",
    "                    \"^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits\"\n",
    "                    \" before being passed to the model.\"\n",
    "                )\n",
    "            return new_inputs\n",
    "\n",
    "\n",
    "    def group_texts(self, examples):\n",
    "        # ['input_ids', 'attention_mask', 'labels']\n",
    "        concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "        return concatenated_examples\n",
    "\n",
    "\n",
    "    def group_ED(self, dataset: Dataset):\n",
    "        results = {\n",
    "            'conv_id': [], \n",
    "            'prompt': [],\n",
    "            'dialog': [], \n",
    "            'context': [],\n",
    "        }\n",
    "        for i, instance in enumerate(dataset):\n",
    "            if instance['utterance_idx'] == 1:\n",
    "                results['conv_id'].append(instance['conv_id'])\n",
    "                results['dialog'].append([])\n",
    "                results['prompt'].append(instance['prompt'])\n",
    "                results['context'].append(instance['context'])\n",
    "\n",
    "            response = {'text': instance['utterance'], 'speaker_idx': instance['speaker_idx']}\n",
    "            results['dialog'][-1].append(response)\n",
    "        return Dataset.from_dict(results)\n",
    "\n",
    "\n",
    "    def preprocess(self, dataset: Dataset):\n",
    "        if self.dataset == \"empathetic_dialogues\":\n",
    "            dataset = self.group_ED(dataset)\n",
    "\n",
    "        dataset = dataset.map(\n",
    "            self.tokenize_and_align_labels,\n",
    "            batched=False,\n",
    "            num_proc=self.preprocessing_num_workers,\n",
    "            remove_columns=dataset.column_names,\n",
    "            load_from_cache_file=not self.overwrite_cache,\n",
    "        )\n",
    "        dataset = dataset.map(\n",
    "            self.group_texts,\n",
    "            batched=True,\n",
    "            num_proc=self.preprocessing_num_workers,\n",
    "            load_from_cache_file=not self.overwrite_cache,\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../../DG_ckpt/bart'\n",
    "data_n = 'blended_skill_talk'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "sp_token = tokenizer.eos_token\n",
    "datasets = load_dataset(data_n)\n",
    "train_dataset = datasets['train']\n",
    "val_dataset = datasets['validation']\n",
    "test_dataset = datasets['test']\n",
    "dg = DGDataset(\n",
    "    dataset=\"blended_skill_talk\",\n",
    "    task=\"seq2seq\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    dataset: Dataset, \n",
    "    tokenizer: Union[BertTokenizer, BartTokenizer, T5Tokenizer, GPT2Tokenizer],\n",
    "): \n",
    "    processed = []\n",
    "    for i, ins in tqdm(enumerate(dataset)):\n",
    "        num_entries, total_entries, context, prev_utt_pc = dg.prepare_context(ins)\n",
    "        for entry_idx in range(num_entries):\n",
    "            free_message, guided_message, original_context, references = dg.prepare_entry(\n",
    "                ins, \n",
    "                entry_idx, \n",
    "                context, \n",
    "                prev_utt_pc,\n",
    "                total_entries,\n",
    "            )\n",
    "            if guided_message is None:\n",
    "                continue\n",
    "            \n",
    "            prev_utt_pc += [\n",
    "                free_message,\n",
    "                guided_message,\n",
    "            ]\n",
    "            \n",
    "            # Original generation\n",
    "            text = original_context + sp_token + free_message\n",
    "            for ref in references:\n",
    "                processed.append({\n",
    "                    'src': text,\n",
    "                    'tgt': ref,\n",
    "                    'src_len': len(tokenizer.tokenize(text)),\n",
    "                    'tgt_len': len(tokenizer.tokenize(ref)),\n",
    "                })\n",
    "            # processed.append({\n",
    "            #     'input': text,\n",
    "            #     'references': references,\n",
    "            #     'input_length': len(tokenizer.tokenize(text)),\n",
    "            #     'references_length': [len(tokenizer.tokenize(ref)) for ref in references],\n",
    "            # })\n",
    "    processed = pd.DataFrame(processed, columns=['src', 'tgt', 'src_len', 'tgt_len'])\n",
    "    return processed\n",
    "\n",
    "data_dir = '../datasets'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "else:\n",
    "    if os.path.exists(f'{data_dir}/train.tsv'):\n",
    "        processed_train = pd.read_csv(f'{data_dir}/train.tsv', sep='\\t')\n",
    "    else:\n",
    "        processed_train = preprocess(train_dataset, tokenizer)\n",
    "        processed_train.to_csv(f'{data_dir}/train.tsv', sep='\\t', index=False)\n",
    "    if os.path.exists(f'{data_dir}/val.tsv'):\n",
    "        processed_val = pd.read_csv(f'{data_dir}/val.tsv', sep='\\t')\n",
    "    else:\n",
    "        processed_val = preprocess(val_dataset, tokenizer)\n",
    "        processed_val.to_csv(f'{data_dir}/val.tsv', sep='\\t', index=False)\n",
    "    if os.path.exists(f'{data_dir}/dev.tsv'):\n",
    "        processed_test = pd.read_csv(f'{data_dir}/dev.tsv', sep='\\t')\n",
    "    else:\n",
    "        processed_test = preprocess(test_dataset, tokenizer)\n",
    "        processed_test.to_csv(f'{data_dir}/dev.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = \"i love acting ! i'll be famous someday . what do you do ?\"\n",
    "inputs = tokenizer(tgt, return_tensors=\"pt\", max_length=128, truncation=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a light-weight model to predict the length of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_train_df = processed_test.groupby('src', as_index=False).agg(list)\n",
    "grouped_val_df = processed_val.groupby('src', as_index=False).agg(list)\n",
    "grouped_test_df = processed_test.groupby('src', as_index=False).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq.models import EncoderRNN, DecoderRNN, Seq2seq\n",
    "\n",
    "model_path = '../../DG_ckpt/bart'\n",
    "data_n = 'blended_skill_talk'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "max_len = 128\n",
    "hidden_size = 256\n",
    "input_dropout = 0\n",
    "dropout = 0.2\n",
    "n_layers = 1\n",
    "bidirectional = True\n",
    "rnn_cell = 'gru'\n",
    "attention = False\n",
    "\n",
    "\n",
    "encoder = EncoderRNN(\n",
    "    vocab_size=tokenizer.__len__(), \n",
    "    max_len=max_len, \n",
    "    hidden_size=hidden_size,\n",
    "    input_dropout_p=input_dropout,\n",
    "    dropout_p=dropout,\n",
    "    n_layers=n_layers,\n",
    "    bidirectional=bidirectional, \n",
    "    rnn_cell=rnn_cell,\n",
    ")\n",
    "decoder = DecoderRNN(\n",
    "    vocab_size=tokenizer.__len__(), \n",
    "    max_len=max_len, \n",
    "    hidden_size=hidden_size * 2 if bidirectional else hidden_size,\n",
    "    sos_id=tokenizer.bos_token_id,\n",
    "    eos_id=tokenizer.eos_token_id,\n",
    "    input_dropout_p=input_dropout,\n",
    "    dropout_p=dropout,\n",
    "    n_layers=n_layers,\n",
    "    bidirectional=bidirectional,\n",
    "    rnn_cell=rnn_cell,\n",
    "    use_attention=attention,\n",
    ")\n",
    "model = Seq2seq(encoder, decoder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = 'bert-base-uncased'\n",
    "# config = AutoConfig.from_pretrained(model_path)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# model = AutoModel.from_pretrained(model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_feature(text: Union[str, List[str]], max_len: int = 256):\n",
    "#     inputs = tokenizer(\n",
    "#         text, \n",
    "#         return_tensors=\"pt\", \n",
    "#         max_length=max_len, \n",
    "#         padding=True,\n",
    "#         truncation=True,\n",
    "#     )\n",
    "#     input_ids = inputs['input_ids']\n",
    "#     embed = model.embeddings.word_embeddings.weight\n",
    "#     return embed[input_ids].detach().numpy()\n",
    "\n",
    "# src_embeds = get_feature(grouped_train_df['src'].tolist())\n",
    "# print(src_embeds.shape) # B x T x D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_encoder = SentenceEncoder(device='cuda')\n",
    "\n",
    "train_src_embeds = sent_encoder.encode(grouped_train_df['src'].tolist())\n",
    "val_src_embeds = sent_encoder.encode(grouped_val_df['src'].tolist())\n",
    "test_src_embeds = sent_encoder.encode(grouped_test_df['src'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_src_embeds.detach().cpu().numpy()\n",
    "Y_train = grouped_train_df['tgt_len'].apply(lambda x: np.mean(x)).to_numpy(dtype=np.float32)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "\n",
    "X_val = val_src_embeds.detach().cpu().numpy()\n",
    "Y_val = grouped_val_df['tgt_len'].apply(lambda x: np.mean(x)).to_numpy(dtype=np.float32)\n",
    "print(X_val.shape, Y_val.shape)\n",
    "\n",
    "X_test = test_src_embeds.detach().cpu().numpy()\n",
    "Y_test = grouped_test_df['tgt_len'].apply(lambda x: np.mean(x)).to_numpy(dtype=np.float32)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.predict(sent_encoder.encode(['i love acting ! i\\'ll be famous someday . what do you do ?']).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = regr.predict(X_test)\n",
    "pred_test_score = regr.score(X_test, Y_test) # the coefficient of determination of the prediction\n",
    "print('test coefficent: ', pred_test_score)\n",
    "\n",
    "pred_val = regr.predict(X_val)\n",
    "pred_val_score = regr.score(X_val, Y_val) # the coefficient of determination of the prediction\n",
    "print('val coefficent: ', pred_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression line to the data\n",
    "coefficients = np.polyfit(pred_test, Y_test, 1)\n",
    "p = np.poly1d(coefficients)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(pred_test, Y_test, 'o', label='data')\n",
    "plt.plot(pred_test, p(pred_test), '-', label='fit')\n",
    "plt.xlabel('Uncertainty')\n",
    "plt.ylabel('Length')\n",
    "plt.savefig('../figures/uncertainty_length.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using rule-based features to predict the length of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def output_score1(input_sentence):\n",
    "    # Parse the input sentence with a NLP tool\n",
    "    doc = nlp(input_sentence)\n",
    "\n",
    "    # Calculate a base score based on the number of words\n",
    "    num_words = len(doc)\n",
    "    base_score = num_words / 30  # Assumes that an average sentence length is around 30 words\n",
    "\n",
    "    # Adjust the score based on the linguistic properties of the input sentence\n",
    "    for token in doc:\n",
    "        # Increase score for longer words\n",
    "        if len(token.text) > 6:\n",
    "            base_score += 0.1\n",
    "\n",
    "        # Increase score for complex syntactic structures\n",
    "        if token.dep_ in [\"ccomp\", \"xcomp\", \"advcl\", \"relcl\", \"acl\"]:\n",
    "            base_score += 0.2\n",
    "\n",
    "        # Increase score for ambiguous or multi-interpretation sentences\n",
    "        if token.pos_ in [\"VERB\", \"NOUN\", \"ADJ\"]:\n",
    "            for child in token.children:\n",
    "                if child.pos_ == \"NOUN\" or child.pos_ == \"ADJ\":\n",
    "                    base_score += 0.1\n",
    "                if child.dep_ == \"advmod\":\n",
    "                    base_score += 0.1\n",
    "\n",
    "        # Increase score for dense information sentences\n",
    "        if token.pos_ == \"NOUN\" or token.pos_ == \"VERB\":\n",
    "            if len(token.text) > 4:\n",
    "                base_score += 0.1\n",
    "                \n",
    "    return base_score\n",
    "\n",
    "\n",
    "def output_score2(input_sentence):\n",
    "    score = 0\n",
    "    \n",
    "    # Check for open-ended questions\n",
    "    if input_sentence.endswith(\"?\"):\n",
    "        score += 2\n",
    "        \n",
    "    # Check for ambiguous or vague language\n",
    "    if len(input_sentence.split()) > 10:\n",
    "        score += 1\n",
    "        \n",
    "    # Check for multi-part questions\n",
    "    num_commas = len(re.findall(\",\", input_sentence))\n",
    "    num_and = len(re.findall(\" and \", input_sentence))\n",
    "    if num_commas > 0 or num_and > 0:\n",
    "        score += num_commas + num_and\n",
    "        \n",
    "    # Check for unfamiliar or complex terminology\n",
    "    doc = nlp(input_sentence)\n",
    "    tech_terms = [\"epigenetics\", \"gene expression\", \"artificial intelligence\", \"machine learning\"]\n",
    "    num_tech_terms = sum([1 for token in doc if token.text.lower() in tech_terms])\n",
    "    score += num_tech_terms\n",
    "    \n",
    "    # Check for abstract or philosophical concepts\n",
    "    abs_terms = [\"consciousness\", \"self\", \"reality\", \"ontology\", \"phenomenology\"]\n",
    "    num_abs_terms = sum([1 for token in doc if token.text.lower() in abs_terms])\n",
    "    score += num_abs_terms\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def output_score3(input_sentence):\n",
    "    score = 0\n",
    "    \n",
    "    # Check for open-ended questions\n",
    "    if input_sentence.endswith(\"?\"):\n",
    "        score += 2\n",
    "        \n",
    "    # Check for ambiguous or vague language\n",
    "    if len(input_sentence.split()) > 10:\n",
    "        score += 1\n",
    "        \n",
    "    # Check for multi-part questions\n",
    "    num_commas = len(re.findall(\",\", input_sentence))\n",
    "    num_and = len(re.findall(\" and \", input_sentence))\n",
    "    if num_commas > 0 or num_and > 0:\n",
    "        score += num_commas + num_and\n",
    "        \n",
    "    # Check for unfamiliar or complex terminology\n",
    "    doc = nlp(input_sentence)\n",
    "    for token in doc:\n",
    "        if token.lemma_ in [\"epigenetic\", \"gene expression\"]:\n",
    "            score += 3\n",
    "        \n",
    "    # Check for abstract or philosophical concepts\n",
    "    if \"nature of consciousness\" in input_sentence or \"self and the world\" in input_sentence:\n",
    "        score += 4\n",
    "        \n",
    "    # Tokenize input sentence\n",
    "    tokens = word_tokenize(input_sentence)\n",
    "    \n",
    "    # Count number of tokens\n",
    "    num_tokens = len(tokens)\n",
    "    \n",
    "    # Calculate average length of tokens\n",
    "    avg_token_length = sum(len(token) for token in tokens) / num_tokens\n",
    "    \n",
    "    # Adjust score based on token length\n",
    "    if avg_token_length > 8:\n",
    "        score += 1\n",
    "    elif avg_token_length > 10:\n",
    "        score += 2\n",
    "    elif avg_token_length > 12:\n",
    "        score += 3\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_UE_predict(df: pd.DataFrame, func: Callable):\n",
    "    rule_ue = df['src'].apply(func)\n",
    "    xx, yy = [], []\n",
    "    for i, row in df.iterrows():\n",
    "        xx.extend([rule_ue[i]] * len(row['tgt_len']))\n",
    "        yy.extend(row['tgt_len'])\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression line to the data\n",
    "def fit_data(xx, yy):\n",
    "    coefficients = np.polyfit(xx, yy, 1)\n",
    "    p = np.poly1d(coefficients)\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.plot(xx, yy, 'o', label='data')\n",
    "    plt.plot(xx, p(xx), '-', label='fit')\n",
    "    plt.xlabel('Uncertainty')\n",
    "    plt.ylabel('Length')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx1, yy1 = rule_UE_predict(grouped_test_df, output_score1)\n",
    "xx2, yy2 = rule_UE_predict(grouped_test_df, output_score2)\n",
    "xx3, yy3 = rule_UE_predict(grouped_test_df, output_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data(xx1, yy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data(xx2, yy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data(xx3, yy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ended_question_score(input_sentence):\n",
    "    if input_sentence.endswith(\"?\"):\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def ambiguous_language_score(input_sentence):\n",
    "    if len(input_sentence.split()) > 10:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def multi_part_question_score(input_sentence):\n",
    "    num_commas = len(re.findall(\",\", input_sentence))\n",
    "    num_and = len(re.findall(\" and \", input_sentence))\n",
    "    num_parts = num_commas + num_and\n",
    "    return num_parts * 0.5\n",
    "\n",
    "def unfamiliar_terminology_score(input_sentence):\n",
    "    doc = nlp(input_sentence)\n",
    "    unfamiliar_terms = 0\n",
    "    for token in doc:\n",
    "        if token.lemma_ in [\"epigenetic\", \"gene expression\", \"quantum mechanics\", \"neuroplasticity\", \"postmodernism\"]:\n",
    "            unfamiliar_terms += 1\n",
    "    return unfamiliar_terms * 0.5\n",
    "\n",
    "def abstract_concepts_score(input_sentence):\n",
    "    if \"nature of consciousness\" in input_sentence or \"self and the world\" in input_sentence or \"meaning of life\" in input_sentence:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def token_length_score(input_sentence):\n",
    "    tokens = word_tokenize(input_sentence)\n",
    "    num_tokens = len(tokens)\n",
    "    avg_token_length = sum(len(token) for token in tokens) / num_tokens\n",
    "    if avg_token_length > 12:\n",
    "        return 1.0\n",
    "    elif avg_token_length > 10:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def input_length_score(input_sentence):\n",
    "    if len(input_sentence) > 200:\n",
    "        return 1.0\n",
    "    elif len(input_sentence) > 100:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def output_score4(input_sentence):\n",
    "    score = open_ended_question_score(input_sentence)\n",
    "    score += ambiguous_language_score(input_sentence)\n",
    "    score += multi_part_question_score(input_sentence)\n",
    "    score += unfamiliar_terminology_score(input_sentence)\n",
    "    score += abstract_concepts_score(input_sentence)\n",
    "    score += token_length_score(input_sentence)\n",
    "    score += input_length_score(input_sentence)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx4, yy4 = rule_UE_predict(grouped_test_df, open_ended_question_score)\n",
    "xx5, yy5 = rule_UE_predict(grouped_test_df, ambiguous_language_score)\n",
    "xx6, yy6 = rule_UE_predict(grouped_test_df, multi_part_question_score)\n",
    "xx7, yy7 = rule_UE_predict(grouped_test_df, token_length_score)\n",
    "xx8, yy8 = rule_UE_predict(grouped_test_df, input_length_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data(xx4, yy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data(xx5, yy5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data(xx6, yy6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data(xx8, yy8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>src</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_len</th>\n",
       "      <th>refs</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge</th>\n",
       "      <th>meteor</th>\n",
       "      <th>infer_time</th>\n",
       "      <th>lw_ue</th>\n",
       "      <th>lw_time</th>\n",
       "      <th>rule1_ue</th>\n",
       "      <th>rule1_time</th>\n",
       "      <th>rule2_ue</th>\n",
       "      <th>rule2_time</th>\n",
       "      <th>rule3_ue</th>\n",
       "      <th>rule3_time</th>\n",
       "      <th>rule4_ue</th>\n",
       "      <th>rule4_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>&lt;PS&gt;i am a grandparent at 44.&lt;SEP&gt;what do you ...</td>\n",
       "      <td>No i do not. But i wish someday after getting ...</td>\n",
       "      <td>23</td>\n",
       "      <td>['no my daughters . do you have any children ?...</td>\n",
       "      <td>0.081041</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.506592</td>\n",
       "      <td>3.048796</td>\n",
       "      <td>[14.578398]</td>\n",
       "      <td>0.186359</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>0.289377</td>\n",
       "      <td>6</td>\n",
       "      <td>0.474823</td>\n",
       "      <td>6</td>\n",
       "      <td>0.238815</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.259709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>&lt;PS&gt;i am a grandparent at 44.&lt;SEP&gt;what do you ...</td>\n",
       "      <td>I love to read. What about you?</td>\n",
       "      <td>9</td>\n",
       "      <td>['i am a night lover and worked 2nd shift sinc...</td>\n",
       "      <td>0.158279</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.179710</td>\n",
       "      <td>1.766788</td>\n",
       "      <td>[17.29737]</td>\n",
       "      <td>0.334299</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>0.335512</td>\n",
       "      <td>7</td>\n",
       "      <td>0.255143</td>\n",
       "      <td>7</td>\n",
       "      <td>0.503494</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.453187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bart</td>\n",
       "      <td>&lt;PS&gt;i am a grandparent at 44.&lt;SEP&gt;what do you ...</td>\n",
       "      <td>I think it will be something that he will real...</td>\n",
       "      <td>25</td>\n",
       "      <td>['maybe . my two daughters would enjoy that . ...</td>\n",
       "      <td>0.068716</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>4.096246</td>\n",
       "      <td>[23.189583]</td>\n",
       "      <td>0.613650</td>\n",
       "      <td>12.466667</td>\n",
       "      <td>0.656929</td>\n",
       "      <td>8</td>\n",
       "      <td>0.336986</td>\n",
       "      <td>8</td>\n",
       "      <td>0.512887</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.473931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bart</td>\n",
       "      <td>&lt;PS&gt;i am a grandparent at 44.&lt;SEP&gt;what do you ...</td>\n",
       "      <td>Good idea! I hope to teach soccer to my son as...</td>\n",
       "      <td>14</td>\n",
       "      <td>['i love photos ! you take them in your hometo...</td>\n",
       "      <td>0.111149</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>2.026502</td>\n",
       "      <td>[23.189583]</td>\n",
       "      <td>0.395968</td>\n",
       "      <td>17.733333</td>\n",
       "      <td>0.599669</td>\n",
       "      <td>7</td>\n",
       "      <td>0.469609</td>\n",
       "      <td>7</td>\n",
       "      <td>0.474061</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.456050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bart</td>\n",
       "      <td>&lt;PS&gt;i am a grandparent at 44.&lt;SEP&gt;what do you ...</td>\n",
       "      <td>Good idea! I hope to teach soccer to my son as...</td>\n",
       "      <td>14</td>\n",
       "      <td>['i love photos ! you take them in your hometo...</td>\n",
       "      <td>0.111149</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.098522</td>\n",
       "      <td>2.276340</td>\n",
       "      <td>[23.189583]</td>\n",
       "      <td>0.296657</td>\n",
       "      <td>22.566667</td>\n",
       "      <td>0.401792</td>\n",
       "      <td>12</td>\n",
       "      <td>0.679572</td>\n",
       "      <td>12</td>\n",
       "      <td>0.404660</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.419896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model                                                src  \\\n",
       "0  bart  <PS>i am a grandparent at 44.<SEP>what do you ...   \n",
       "1  bart  <PS>i am a grandparent at 44.<SEP>what do you ...   \n",
       "2  bart  <PS>i am a grandparent at 44.<SEP>what do you ...   \n",
       "3  bart  <PS>i am a grandparent at 44.<SEP>what do you ...   \n",
       "4  bart  <PS>i am a grandparent at 44.<SEP>what do you ...   \n",
       "\n",
       "                                                pred  pred_len  \\\n",
       "0  No i do not. But i wish someday after getting ...        23   \n",
       "1                    I love to read. What about you?         9   \n",
       "2  I think it will be something that he will real...        25   \n",
       "3  Good idea! I hope to teach soccer to my son as...        14   \n",
       "4  Good idea! I hope to teach soccer to my son as...        14   \n",
       "\n",
       "                                                refs      bleu     rouge  \\\n",
       "0  ['no my daughters . do you have any children ?...  0.081041  0.296296   \n",
       "1  ['i am a night lover and worked 2nd shift sinc...  0.158279  0.153846   \n",
       "2  ['maybe . my two daughters would enjoy that . ...  0.068716  0.121212   \n",
       "3  ['i love photos ! you take them in your hometo...  0.111149  0.095238   \n",
       "4  ['i love photos ! you take them in your hometo...  0.111149  0.173913   \n",
       "\n",
       "     meteor  infer_time        lw_ue   lw_time   rule1_ue  rule1_time  \\\n",
       "0  0.506592    3.048796  [14.578398]  0.186359   5.566667    0.289377   \n",
       "1  0.179710    1.766788   [17.29737]  0.334299   7.666667    0.335512   \n",
       "2  0.128205    4.096246  [23.189583]  0.613650  12.466667    0.656929   \n",
       "3  0.088496    2.026502  [23.189583]  0.395968  17.733333    0.599669   \n",
       "4  0.098522    2.276340  [23.189583]  0.296657  22.566667    0.401792   \n",
       "\n",
       "   rule2_ue  rule2_time  rule3_ue  rule3_time  rule4_ue  rule4_time  \n",
       "0         6    0.474823         6    0.238815       4.0    0.259709  \n",
       "1         7    0.255143         7    0.503494       4.5    0.453187  \n",
       "2         8    0.336986         8    0.512887       5.0    0.473931  \n",
       "3         7    0.469609         7    0.474061       4.5    0.456050  \n",
       "4        12    0.679572        12    0.404660       7.0    0.419896  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_df = pd.read_csv(\"../results/bart_BST_10.csv\")\n",
    "bart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
